"""
å¤šç®—æ³•å¯¹æ¯”å¯è§†åŒ–æ¨¡å—
ç”ŸæˆAutoGen vs 4ç§åŸºçº¿ç®—æ³•çš„å¯¹æ¯”å›¾è¡¨
"""

import json
import matplotlib.pyplot as plt
import matplotlib
import numpy as np
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
matplotlib.rcParams['axes.unicode_minus'] = False


class MultiAlgorithmVisualizer:
    """å¤šç®—æ³•å¯¹æ¯”å¯è§†åŒ–å™¨"""
    
    def __init__(self, comparison_file='comparison_results/all_algorithms_comparison.json'):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            comparison_file: å¯¹æ¯”ç»“æœJSONæ–‡ä»¶è·¯å¾„
        """
        self.comparison_file = comparison_file
        self.output_dir = "comparison_visualizations"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        # ç®—æ³•é…ç½®
        self.algo_config = {
            'autogen': {'name': 'AutoGen', 'color': '#2E86AB', 'marker': 'o'},
            'greedy': {'name': 'è´ªå¿ƒç®—æ³•', 'color': '#A23B72', 'marker': 's'},
            'random': {'name': 'éšæœºåˆ†é…', 'color': '#F18F01', 'marker': '^'},
            'genetic': {'name': 'é—ä¼ ç®—æ³•', 'color': '#C73E1D', 'marker': 'D'},
            'ip': {'name': 'æ•´æ•°è§„åˆ’', 'color': '#6A994E', 'marker': 'v'}
        }
        
        # åŠ è½½å¯¹æ¯”æ•°æ®
        self.load_data()
    
    def load_data(self):
        """åŠ è½½å¯¹æ¯”æ•°æ®"""
        with open(self.comparison_file, 'r', encoding='utf-8') as f:
            self.data = json.load(f)
    
    def plot_overall_comparison(self):
        """ç»˜åˆ¶æ€»ä½“è¯„åˆ†å¯¹æ¯”æ¡å½¢å›¾"""
        fig, ax = plt.subplots(figsize=(12, 7))
        
        algorithms = self.data['algorithms']
        scores = [self.data['results'][algo]['overall_score'] for algo in algorithms]
        names = [self.algo_config[algo]['name'] for algo in algorithms]
        colors = [self.algo_config[algo]['color'] for algo in algorithms]
        
        bars = ax.bar(range(len(algorithms)), scores, color=colors, 
                     edgecolor='black', linewidth=2, alpha=0.8)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, score) in enumerate(zip(bars, scores)):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                   f'{score:.2f}',
                   ha='center', va='bottom', size=13, weight='bold')
        
        ax.set_ylabel('æ€»ä½“è¯„åˆ†', size=14, weight='bold')
        ax.set_xlabel('ç®—æ³•', size=14, weight='bold')
        ax.set_title('æ‰€æœ‰ç®—æ³•æ€»ä½“è¯„åˆ†å¯¹æ¯”', size=16, weight='bold', pad=20)
        ax.set_xticks(range(len(algorithms)))
        ax.set_xticklabels(names, rotation=15, ha='right')
        ax.set_ylim(0, 100)
        ax.grid(axis='y', alpha=0.3, linestyle='--')
        
        # æ·»åŠ å¹³å‡çº¿
        avg_score = np.mean(scores)
        ax.axhline(y=avg_score, color='red', linestyle='--', 
                  linewidth=2, alpha=0.7, label=f'å¹³å‡åˆ†: {avg_score:.2f}')
        ax.legend(fontsize=11)
        
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/all_1_overall_scores.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ“ æ€»ä½“è¯„åˆ†å¯¹æ¯”: {self.output_dir}/all_1_overall_scores.png")
    
    def plot_radar_comparison(self):
        """ç»˜åˆ¶å¤šç®—æ³•é›·è¾¾å›¾å¯¹æ¯”"""
        fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(projection='polar'))
        
        categories = ['ä»»åŠ¡å®Œæˆç‡', 'æ—¶é—´æ•ˆç‡', 'èµ„æºåˆ©ç”¨', 'çº¦æŸæ»¡è¶³']
        num_vars = len(categories)
        
        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
        angles += angles[:1]
        
        # ç»˜åˆ¶æ¯ä¸ªç®—æ³•
        for algo in self.data['algorithms']:
            result = self.data['results'][algo]
            values = [
                result['task_completion_rate'],
                result['time_efficiency'],
                result['resource_utilization'],
                result['constraint_satisfaction']
            ]
            values += values[:1]
            
            config = self.algo_config[algo]
            ax.plot(angles, values, config['marker'] + '-', 
                   linewidth=2.5, label=config['name'], 
                   color=config['color'], markersize=8)
            ax.fill(angles, values, alpha=0.15, color=config['color'])
        
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, size=13)
        ax.set_ylim(0, 100)
        ax.set_yticks([20, 40, 60, 80, 100])
        ax.set_yticklabels(['20', '40', '60', '80', '100'], size=11)
        ax.grid(True, linestyle='--', alpha=0.7)
        
        plt.title('å¤šç®—æ³•æ€§èƒ½é›·è¾¾å›¾å¯¹æ¯”', size=18, weight='bold', pad=30)
        plt.legend(loc='upper right', bbox_to_anchor=(1.35, 1.1), fontsize=12)
        
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/all_2_radar_chart.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ“ é›·è¾¾å›¾å¯¹æ¯”: {self.output_dir}/all_2_radar_chart.png")
    
    def plot_metrics_heatmap(self):
        """ç»˜åˆ¶è¯„ä¼°æŒ‡æ ‡çƒ­åŠ›å›¾"""
        fig, ax = plt.subplots(figsize=(14, 8))
        
        algorithms = self.data['algorithms']
        metrics = ['ä»»åŠ¡å®Œæˆç‡', 'æ—¶é—´æ•ˆç‡', 'èµ„æºåˆ©ç”¨', 'çº¦æŸæ»¡è¶³', 'æ€»ä½“è¯„åˆ†']
        
        # æ„å»ºæ•°æ®çŸ©é˜µ
        data_matrix = []
        for algo in algorithms:
            result = self.data['results'][algo]
            row = [
                result['task_completion_rate'],
                result['time_efficiency'],
                result['resource_utilization'],
                result['constraint_satisfaction'],
                result['overall_score']
            ]
            data_matrix.append(row)
        
        data_matrix = np.array(data_matrix)
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        im = ax.imshow(data_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)
        
        # è®¾ç½®åˆ»åº¦
        ax.set_xticks(np.arange(len(metrics)))
        ax.set_yticks(np.arange(len(algorithms)))
        ax.set_xticklabels(metrics, size=12)
        ax.set_yticklabels([self.algo_config[a]['name'] for a in algorithms], size=12)
        
        # æ—‹è½¬xè½´æ ‡ç­¾
        plt.setp(ax.get_xticklabels(), rotation=15, ha="right", rotation_mode="anchor")
        
        # æ·»åŠ æ•°å€¼
        for i in range(len(algorithms)):
            for j in range(len(metrics)):
                text = ax.text(j, i, f'{data_matrix[i, j]:.1f}',
                             ha="center", va="center", color="black", 
                             size=11, weight='bold')
        
        ax.set_title('ç®—æ³•æ€§èƒ½çƒ­åŠ›å›¾ï¼ˆæ•°å€¼è¶Šé«˜è¶Šå¥½ï¼‰', size=16, weight='bold', pad=20)
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(im, ax=ax)
        cbar.set_label('è¯„åˆ†', size=12, weight='bold')
        
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/all_3_heatmap.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ“ çƒ­åŠ›å›¾: {self.output_dir}/all_3_heatmap.png")
    
    def plot_detailed_comparison(self):
        """ç»˜åˆ¶è¯¦ç»†å¯¹æ¯”æŸ±çŠ¶å›¾"""
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        metrics_config = [
            ('task_completion_rate', 'ä»»åŠ¡å®Œæˆç‡ (%)'),
            ('time_efficiency', 'æ—¶é—´æ•ˆç‡'),
            ('resource_utilization', 'èµ„æºåˆ©ç”¨'),
            ('constraint_satisfaction', 'çº¦æŸæ»¡è¶³')
        ]
        
        for idx, (metric_key, metric_name) in enumerate(metrics_config):
            ax = axes[idx // 2, idx % 2]
            
            algorithms = self.data['algorithms']
            values = [self.data['results'][algo][metric_key] for algo in algorithms]
            names = [self.algo_config[algo]['name'] for algo in algorithms]
            colors = [self.algo_config[algo]['color'] for algo in algorithms]
            
            bars = ax.bar(range(len(algorithms)), values, color=colors, 
                         edgecolor='black', linewidth=1.5, alpha=0.8)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, value in zip(bars, values):
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                       f'{value:.1f}',
                       ha='center', va='bottom', size=11, weight='bold')
            
            ax.set_ylabel('è¯„åˆ†', size=12, weight='bold')
            ax.set_title(metric_name, size=14, weight='bold')
            ax.set_xticks(range(len(algorithms)))
            ax.set_xticklabels(names, rotation=20, ha='right', size=10)
            ax.set_ylim(0, 105)
            ax.grid(axis='y', alpha=0.3)
        
        plt.suptitle('å„ç»´åº¦è¯¦ç»†å¯¹æ¯”', size=18, weight='bold', y=0.995)
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/all_4_detailed_metrics.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ“ è¯¦ç»†å¯¹æ¯”å›¾: {self.output_dir}/all_4_detailed_metrics.png")
    
    def plot_ranking_comparison(self):
        """ç»˜åˆ¶ç®—æ³•æ’åå¯¹æ¯”"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))
        
        # å·¦å›¾ï¼šæŒ‰æ€»åˆ†æ’åºçš„æ¨ªå‘æ¡å½¢å›¾
        algorithms = self.data['algorithms']
        scores = [self.data['results'][algo]['overall_score'] for algo in algorithms]
        
        # æ’åº
        sorted_pairs = sorted(zip(algorithms, scores), key=lambda x: x[1])
        sorted_algos, sorted_scores = zip(*sorted_pairs)
        
        names = [self.algo_config[algo]['name'] for algo in sorted_algos]
        colors = [self.algo_config[algo]['color'] for algo in sorted_algos]
        
        y_pos = np.arange(len(sorted_algos))
        bars = ax1.barh(y_pos, sorted_scores, color=colors, 
                       edgecolor='black', linewidth=2, alpha=0.8)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, score) in enumerate(zip(bars, sorted_scores)):
            width = bar.get_width()
            rank = len(sorted_algos) - i
            medal = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else ""
            ax1.text(width + 1, bar.get_y() + bar.get_height()/2.,
                    f'{score:.2f} {medal}',
                    ha='left', va='center', size=13, weight='bold')
        
        ax1.set_yticks(y_pos)
        ax1.set_yticklabels(names, size=12)
        ax1.set_xlabel('æ€»ä½“è¯„åˆ†', size=13, weight='bold')
        ax1.set_title('ç®—æ³•æ’åï¼ˆæŒ‰æ€»åˆ†ï¼‰', size=14, weight='bold')
        ax1.set_xlim(0, 100)
        ax1.grid(axis='x', alpha=0.3)
        
        # å³å›¾ï¼šè¿è¡Œæ—¶é—´å¯¹æ¯”
        runtimes = [self.data['results'][algo]['runtime'] for algo in algorithms]
        names_all = [self.algo_config[algo]['name'] for algo in algorithms]
        colors_all = [self.algo_config[algo]['color'] for algo in algorithms]
        
        bars2 = ax2.bar(range(len(algorithms)), runtimes, color=colors_all,
                       edgecolor='black', linewidth=1.5, alpha=0.8)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, runtime in zip(bars2, runtimes):
            height = bar.get_height()
            if runtime < 1:
                label = f'{runtime*1000:.1f}ms'
            else:
                label = f'{runtime:.2f}s'
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    label,
                    ha='center', va='bottom', size=11, weight='bold')
        
        ax2.set_ylabel('è¿è¡Œæ—¶é—´ (ç§’)', size=13, weight='bold')
        ax2.set_title('ç®—æ³•è¿è¡Œæ—¶é—´å¯¹æ¯”', size=14, weight='bold')
        ax2.set_xticks(range(len(algorithms)))
        ax2.set_xticklabels(names_all, rotation=20, ha='right', size=10)
        ax2.grid(axis='y', alpha=0.3)
        ax2.set_yscale('log')  # ä½¿ç”¨å¯¹æ•°åˆ»åº¦
        
        plt.tight_layout()
        plt.savefig(f'{self.output_dir}/all_5_ranking.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ“ æ’åå¯¹æ¯”å›¾: {self.output_dir}/all_5_ranking.png")
    
    def plot_comprehensive_dashboard(self):
        """ç»˜åˆ¶ç»¼åˆå¯¹æ¯”ä»ªè¡¨ç›˜"""
        fig = plt.figure(figsize=(20, 12))
        gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)
        
        algorithms = self.data['algorithms']
        
        # 1. æ€»åˆ†å¯¹æ¯”ï¼ˆå 2åˆ—ï¼‰
        ax1 = fig.add_subplot(gs[0, :2])
        scores = [self.data['results'][algo]['overall_score'] for algo in algorithms]
        names = [self.algo_config[algo]['name'] for algo in algorithms]
        colors = [self.algo_config[algo]['color'] for algo in algorithms]
        
        bars = ax1.bar(range(len(algorithms)), scores, color=colors,
                      edgecolor='black', linewidth=2, alpha=0.8)
        for bar, score in zip(bars, scores):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{score:.1f}',
                    ha='center', va='bottom', size=12, weight='bold')
        
        ax1.set_xticks(range(len(algorithms)))
        ax1.set_xticklabels(names, rotation=15, ha='right')
        ax1.set_ylabel('æ€»ä½“è¯„åˆ†', size=12, weight='bold')
        ax1.set_title('æ€»ä½“è¯„åˆ†å¯¹æ¯”', size=14, weight='bold')
        ax1.set_ylim(0, 100)
        ax1.grid(axis='y', alpha=0.3)
        
        # 2. æœ€ä½³ç®—æ³•å±•ç¤ºï¼ˆå 2åˆ—ï¼‰
        ax2 = fig.add_subplot(gs[0, 2:])
        best = self.data['summary']['best_algorithm']
        ax2.text(0.5, 0.6, 'ğŸ†', ha='center', va='center', size=80)
        ax2.text(0.5, 0.3, best['name'], 
                ha='center', va='center', size=24, weight='bold',
                color=self.algo_config[best['code']]['color'])
        ax2.text(0.5, 0.15, f"æ€»åˆ†: {best['score']:.2f}", 
                ha='center', va='center', size=18, weight='bold')
        ax2.set_xlim(0, 1)
        ax2.set_ylim(0, 1)
        ax2.axis('off')
        ax2.set_title('æœ€ä½³ç®—æ³•', size=14, weight='bold')
        
        # 3-6. å„ç»´åº¦å¯¹æ¯”ï¼ˆ4ä¸ªå­å›¾ï¼‰
        metrics_config = [
            ('task_completion_rate', 'ä»»åŠ¡å®Œæˆç‡'),
            ('time_efficiency', 'æ—¶é—´æ•ˆç‡'),
            ('resource_utilization', 'èµ„æºåˆ©ç”¨'),
            ('constraint_satisfaction', 'çº¦æŸæ»¡è¶³')
        ]
        
        for idx, (metric_key, metric_name) in enumerate(metrics_config):
            ax = fig.add_subplot(gs[1, idx])
            values = [self.data['results'][algo][metric_key] for algo in algorithms]
            
            bars = ax.bar(range(len(algorithms)), values, color=colors,
                         edgecolor='black', linewidth=1, alpha=0.8, width=0.6)
            
            ax.set_xticks(range(len(algorithms)))
            ax.set_xticklabels([n[:4] for n in names], size=9)
            ax.set_title(metric_name, size=11, weight='bold')
            ax.set_ylim(0, 105)
            ax.grid(axis='y', alpha=0.3)
        
        # 7. ç»Ÿè®¡æ‘˜è¦ï¼ˆå 2åˆ—ï¼‰
        ax7 = fig.add_subplot(gs[2, :2])
        summary_text = f"""
        ç»Ÿè®¡æ‘˜è¦
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        æœ€é«˜åˆ†: {self.data['summary']['max_score']:.2f}
        æœ€ä½åˆ†: {self.data['summary']['min_score']:.2f}
        å¹³å‡åˆ†: {self.data['summary']['avg_score']:.2f}
        æ ‡å‡†å·®: {self.data['summary']['std_score']:.2f}
        åˆ†æ•°èŒƒå›´: {self.data['summary']['score_range']:.2f}
        
        å‚ä¸ç®—æ³•: {len(algorithms)} ä¸ª
        """
        ax7.text(0.1, 0.5, summary_text, 
                ha='left', va='center', size=13, 
                family='monospace', weight='bold')
        ax7.set_xlim(0, 1)
        ax7.set_ylim(0, 1)
        ax7.axis('off')
        
        # 8. ç®—æ³•æ’åï¼ˆå 2åˆ—ï¼‰
        ax8 = fig.add_subplot(gs[2, 2:])
        sorted_pairs = sorted(
            [(algo, self.data['results'][algo]['overall_score']) 
             for algo in algorithms],
            key=lambda x: x[1],
            reverse=True
        )
        
        ranking_text = "ç®—æ³•æ’å\n" + "â”"*30 + "\n"
        for rank, (algo, score) in enumerate(sorted_pairs, 1):
            medal = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else f"{rank}."
            ranking_text += f"{medal} {self.algo_config[algo]['name']:<10} {score:>6.2f}åˆ†\n"
        
        ax8.text(0.1, 0.5, ranking_text,
                ha='left', va='center', size=13,
                family='monospace', weight='bold')
        ax8.set_xlim(0, 1)
        ax8.set_ylim(0, 1)
        ax8.axis('off')
        
        # æ€»æ ‡é¢˜
        fig.suptitle('å¤šç®—æ³•ç»¼åˆå¯¹æ¯”ä»ªè¡¨ç›˜', size=20, weight='bold', y=0.98)
        
        plt.savefig(f'{self.output_dir}/all_6_dashboard.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"   âœ“ ç»¼åˆä»ªè¡¨ç›˜: {self.output_dir}/all_6_dashboard.png")
    
    def visualize_all(self):
        """ç”Ÿæˆæ‰€æœ‰å¯¹æ¯”å›¾è¡¨"""
        print("\nğŸ¨ ç”Ÿæˆå¤šç®—æ³•å¯¹æ¯”å¯è§†åŒ–å›¾è¡¨...")
        
        self.plot_overall_comparison()
        self.plot_radar_comparison()
        self.plot_metrics_heatmap()
        self.plot_detailed_comparison()
        self.plot_ranking_comparison()
        self.plot_comprehensive_dashboard()
        
        print(f"\nâœ… æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ°: {self.output_dir}/")


if __name__ == "__main__":
    print("=" * 70)
    print("å¤šç®—æ³•å¯¹æ¯”å¯è§†åŒ–")
    print("=" * 70)
    
    try:
        visualizer = MultiAlgorithmVisualizer()
        visualizer.visualize_all()
        
        print("\n" + "="*70)
        print("âœ¨ å¯è§†åŒ–å®Œæˆï¼")
        print("="*70)
        print("\nç”Ÿæˆçš„å›¾è¡¨:")
        print("  1. all_1_overall_scores.png - æ€»ä½“è¯„åˆ†å¯¹æ¯” â­")
        print("  2. all_2_radar_chart.png - é›·è¾¾å›¾å¯¹æ¯” â­")
        print("  3. all_3_heatmap.png - æ€§èƒ½çƒ­åŠ›å›¾ â­")
        print("  4. all_4_detailed_metrics.png - å„ç»´åº¦è¯¦ç»†å¯¹æ¯”")
        print("  5. all_5_ranking.png - æ’åå’Œè¿è¡Œæ—¶é—´")
        print("  6. all_6_dashboard.png - ç»¼åˆä»ªè¡¨ç›˜ â­")
        
    except FileNotFoundError as e:
        print(f"\nâŒ é”™è¯¯: æœªæ‰¾åˆ°å¯¹æ¯”ç»“æœæ–‡ä»¶")
        print("   è¯·å…ˆè¿è¡Œ: python comparison_all_algorithms.py")
    except Exception as e:
        print(f"\nâŒ å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
